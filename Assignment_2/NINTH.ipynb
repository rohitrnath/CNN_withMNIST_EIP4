{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NINTH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJyVpgSxHt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlEUplvoxKAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6Y9Va-xxMXG",
        "colab_type": "code",
        "outputId": "e242e80f-c878-419f-8f3b-87fedd0788bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[13])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f52ea5dd438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqGAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDZxPhhxOgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzMqbTnxQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdYiW6ixR9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[:10]\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFR0F9j0xVp2",
        "colab_type": "code",
        "outputId": "168eaade-110e-4c27-c013-ddc6f07ee141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpXf4YQxXRm",
        "colab_type": "code",
        "outputId": "3f5d1f58-1614-444a-cf9d-75068a08e8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', use_bias=False)) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', use_bias=False)) #22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "#model.add(Convolution2D(10, 1, 1, activation='relu')) #22\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "#model.add(Convolution2D(8, 1, 1, activation='relu')) #22\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(Convolution2D(16, 3, 3, activation='relu')) #9\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', use_bias=False))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', use_bias=False))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', use_bias=False))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))#11-4\n",
        "\n",
        "# #model.add(Convolution2D(16, 3, 3, activation='relu'))#7\n",
        "# #model.add(BatchNormalization())\n",
        "# #model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# model.add(Convolution2D(8, 1, 1, activation='relu'))#4\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# model.add(Convolution2D(16, 3, 3, activation='relu'))#2\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "#model.add(Convolution2D(10, 4, 4))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu', use_bias=False)) #7\n",
        "\n",
        "model.add(Convolution2D(10, 5))\n",
        "\n",
        "\n",
        "#model.add(Flatten())\n",
        "#model.add(GlobalMaxPooling2D())\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_314 (Conv2D)          (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_213 (Bat (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_220 (Dropout)        (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_315 (Conv2D)          (None, 24, 24, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_214 (Bat (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_221 (Dropout)        (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_316 (Conv2D)          (None, 22, 22, 16)        2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_215 (Bat (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_222 (Dropout)        (None, 22, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 11, 11, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_317 (Conv2D)          (None, 9, 9, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_216 (Bat (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_223 (Dropout)        (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_318 (Conv2D)          (None, 7, 7, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_217 (Bat (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_224 (Dropout)        (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_319 (Conv2D)          (None, 5, 5, 16)          2304      \n",
            "_________________________________________________________________\n",
            "batch_normalization_218 (Bat (None, 5, 5, 16)          64        \n",
            "_________________________________________________________________\n",
            "dropout_225 (Dropout)        (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_320 (Conv2D)          (None, 5, 5, 10)          160       \n",
            "_________________________________________________________________\n",
            "conv2d_321 (Conv2D)          (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_26  (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_39 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,734\n",
            "Trainable params: 14,542\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2IicGJ4x3Be",
        "colab_type": "code",
        "outputId": "7a1704da-fea3-4481-92cb-e6b3912e1383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.015 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.015), metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.015.\n",
            "60000/60000 [==============================] - 31s 515us/step - loss: 0.0859 - acc: 0.9738 - val_loss: 0.0597 - val_acc: 0.9808\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0113722517.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0570 - acc: 0.9823 - val_loss: 0.0459 - val_acc: 0.9860\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0091575092.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0454 - acc: 0.9857 - val_loss: 0.0279 - val_acc: 0.9914\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0076647931.\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0401 - acc: 0.9872 - val_loss: 0.0337 - val_acc: 0.9898\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0065905097.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0355 - acc: 0.9888 - val_loss: 0.0315 - val_acc: 0.9915\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0057803468.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0322 - acc: 0.9892 - val_loss: 0.0214 - val_acc: 0.9939\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0051475635.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0291 - acc: 0.9903 - val_loss: 0.0240 - val_acc: 0.9919\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0046396536.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0281 - acc: 0.9909 - val_loss: 0.0226 - val_acc: 0.9930\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.004222973.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0272 - acc: 0.9912 - val_loss: 0.0252 - val_acc: 0.9922\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0038749677.\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0300 - val_acc: 0.9916\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0035799523.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0240 - acc: 0.9926 - val_loss: 0.0284 - val_acc: 0.9927\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.00332668.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0219 - acc: 0.9927 - val_loss: 0.0266 - val_acc: 0.9935\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0031068766.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0287 - val_acc: 0.9924\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.002914319.\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0208 - acc: 0.9937 - val_loss: 0.0229 - val_acc: 0.9930\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0027442371.\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0230 - val_acc: 0.9935\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0025929127.\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0234 - val_acc: 0.9938\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.002457405.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0220 - val_acc: 0.9940\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0023353573.\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0182 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9946\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0022248591.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0227 - val_acc: 0.9939\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.002124345.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0205 - val_acc: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52e1fd7160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxlW9ufyQiO",
        "colab_type": "code",
        "outputId": "58277244-8f0c-4bef-9b96-fe5ebc056685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.019932233119336888, 0.9947]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qDl21ozBnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}